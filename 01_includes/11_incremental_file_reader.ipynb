{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd446894-d518-48a6-9edb-0e42dcca9553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------\n",
    "# Incremental Reader (Auto Loader)\n",
    "# -------------------------------------------\n",
    "import traceback\n",
    "\n",
    "def read_incremental_data(path: str, file_format: str, schema_evolution_mode: str, job_name: str, logger):\n",
    "    try:\n",
    "        schema_path = f\"{path}/_schema\"\n",
    "        logger.info(f\"{job_name} - Auto Loader init: path={path}, file_format={file_format}, schema_path={schema_path}, schema_evolution_mode={schema_evolution_mode}\")\n",
    "        reader = (spark.readStream\n",
    "                    .format(\"cloudFiles\")\n",
    "                    .option(\"cloudFiles.format\", file_format)\n",
    "                    .option(\"cloudFiles.schemaLocation\", schema_path)\n",
    "                    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "                    .option(\"cloudFiles.schemaEvolutionMode\", schema_evolution_mode))\n",
    "        \n",
    "        if file_format.lower() == \"binaryfile\":\n",
    "            reader = (reader\n",
    "                      .option(\"recursiveFileLookup\", \"true\")  # allow * / * folders\n",
    "                      .option(\"pathGlobFilter\", \"*.png\"))     # only .png files\n",
    "        # Static preview count for debug\n",
    "        try:\n",
    "            static_reader = (spark.read.format(file_format)\n",
    "                                .option(\"recursiveFileLookup\", \"true\") if file_format.lower() == \"binaryfile\" else spark.read.format(file_format))\n",
    "            preview_count = static_reader.load(path).count()\n",
    "            logger.info(f\"{job_name} - Current static count at path: {preview_count:,} rows/files\")\n",
    "        except Exception as ce:\n",
    "            logger.warning(f\"{job_name} - Static preview count failed: {ce}\")\n",
    "\n",
    "        df = reader.load(path)   \n",
    "\n",
    "        logger.info(f\"{job_name} - Auto Loader read stream created.\")\n",
    "        logger.info(f\"{job_name} - Schema: {df.schema.simpleString()}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"{job_name} - Auto Loader read stream failed: {e}\")\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11_incremental_file_reader",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
